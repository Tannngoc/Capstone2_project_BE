from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from webdriver_manager.chrome import ChromeDriverManager
import pandas as pd
import dateparser
from datetime import datetime, timedelta
import os

# C√†i ƒë·∫∑t tr√¨nh duy·ªát headless
options = webdriver.ChromeOptions()
options.add_argument("--headless=new")
options.add_argument("--no-sandbox")
options.add_argument("--disable-dev-shm-usage")

service = Service(ChromeDriverManager().install())
driver = webdriver.Chrome(service=service, options=options)

tickers = ['AAPL', 'IBM', 'TSLA', 'MSFT', 'NVDA']
base_url = "https://finance.yahoo.com/quote/{}/news"
news_data = []

# T√≠nh ng√†y v√† gi·ªù c·ªßa 24 gi·ªù qua
cutoff_time = datetime.now() - timedelta(days=1)

# ƒê·∫£m b·∫£o th∆∞ m·ª•c t·ªìn t·∫°i
output_path = "app/db/news.csv"
os.makedirs(os.path.dirname(output_path), exist_ok=True)

# Ki·ªÉm tra xem file ƒë√£ t·ªìn t·∫°i ch∆∞a v√† n·∫øu c√≥ th√¨ load d·ªØ li·ªáu hi·ªán t·∫°i
if os.path.exists(output_path):
    existing_df = pd.read_csv(output_path)
    existing_titles = set(existing_df['title'] + existing_df['published_date'].astype(str))  # K·∫øt h·ª£p title v√† published_date
else:
    existing_titles = set()

for ticker in tickers:
    print(f"\nüì• Fetching news for {ticker}...")
    url = base_url.format(ticker)
    driver.get(url)

    # L·∫•y to√†n b·ªô c√°c b√†i vi·∫øt tr√™n trang m√† kh√¥ng c·∫ßn cu·ªôn trang
    articles = driver.find_elements(By.CSS_SELECTOR, 'section[role="article"]')

    for article in articles:
        try:
            title_elem = article.find_element(By.TAG_NAME, 'h3')
            title = title_elem.text.strip()

            # L·∫•y th√¥ng tin th·ªùi gian
            pub_info = article.find_element(By.CSS_SELECTOR, 'div.publishing').text.strip()
            if '‚Ä¢' in pub_info:
                _, published_time = map(str.strip, pub_info.split('‚Ä¢', 1))
            else:
                published_time = pub_info.strip()

            # Ph√¢n t√≠ch th·ªùi gian ƒëƒÉng b√†i
            pub_date = dateparser.parse(published_time)
            if pub_date is None or pub_date < cutoff_time:
                continue  # Ch·ªâ l·∫•y tin trong 24 gi·ªù qua

            # T·∫°o kh√≥a duy nh·∫•t ƒë·ªÉ ki·ªÉm tra tr√πng l·∫∑p: s·ª≠ d·ª•ng title v√† published_date
            unique_key = title + pub_date.strftime('%Y-%m-%d')

            # Ki·ªÉm tra tr√πng l·∫∑p d·ª±a tr√™n kh√≥a duy nh·∫•t
            if unique_key in existing_titles:
                continue  # B·ªè qua b√†i vi·∫øt ƒë√£ c√≥

            # L∆∞u tin v√†o danh s√°ch
            news_data.append({
                'company': ticker,
                'title': title,
                'published_date': pub_date.strftime('%Y-%m-%d')
            })

            # Th√™m v√†o set ƒë·ªÉ tr√°nh l∆∞u tr√πng trong qu√° tr√¨nh n√†y
            existing_titles.add(unique_key)

        except Exception as e:
            continue  # B·ªè qua b√†i vi·∫øt c√≥ l·ªói

driver.quit()

# N·∫øu c√≥ d·ªØ li·ªáu m·ªõi, append v√†o file
if news_data:
    new_df = pd.DataFrame(news_data)
    new_df.to_csv(output_path, mode='a', header=not os.path.exists(output_path), index=False, encoding='utf-8-sig')
    print(f"\n‚úÖ ƒê√£ l∆∞u {len(new_df)} b√†i vi·∫øt v√†o '{output_path}'")
else:
    print("\n‚ö†Ô∏è Kh√¥ng c√≥ tin t·ª©c m·ªõi ƒë·ªÉ l∆∞u.")