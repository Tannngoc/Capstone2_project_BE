from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from webdriver_manager.chrome import ChromeDriverManager
import pandas as pd
import dateparser
from datetime import datetime, timedelta
import os
import sys

# C√†i ƒë·∫∑t tr√¨nh duy·ªát headless
options = webdriver.ChromeOptions()
options.add_argument('--headless')
options.add_argument('--no-sandbox')
options.add_argument('--disable-dev-shm-usage')
options.add_argument('--disable-gpu')
options.add_argument('--disable-dev-tools')

try:
    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=options)
except Exception as e:
    print(f"‚ùå Failed to initialize headless Chrome: {e}")
    sys.exit(1)

tickers = ['AAPL', 'IBM', 'TSLA', 'MSFT', 'NVDA']
base_url = "https://finance.yahoo.com/quote/{}/news"
news_data = []

# T√≠nh th·ªùi gian c·∫Øt m·ªëc 24 gi·ªù
cutoff_time = datetime.now() - timedelta(days=1)

# T·∫°o th∆∞ m·ª•c ch·ª©a file n·∫øu ch∆∞a t·ªìn t·∫°i
output_path = "app/db/news.csv"
os.makedirs(os.path.dirname(output_path), exist_ok=True)

# Load d·ªØ li·ªáu c≈© n·∫øu c√≥
if os.path.exists(output_path):
    existing_df = pd.read_csv(output_path)
    existing_titles = set(existing_df['title'] + existing_df['published_date'].astype(str))
else:
    existing_titles = set()

for ticker in tickers:
    print(f"\nüì• Fetching news for {ticker}...")
    url = base_url.format(ticker)
    try:
        driver.get(url)
    except Exception as e:
        print(f"‚ùå Failed to load page for {ticker}: {e}")
        continue

    try:
        articles = driver.find_elements(By.CSS_SELECTOR, 'section[role="article"]')
    except Exception as e:
        print(f"‚ùå Error finding articles for {ticker}: {e}")
        continue

    for article in articles:
        try:
            title_elem = article.find_element(By.TAG_NAME, 'h3')
            title = title_elem.text.strip()

            pub_info = article.find_element(By.CSS_SELECTOR, 'div.publishing').text.strip()
            if '‚Ä¢' in pub_info:
                _, published_time = map(str.strip, pub_info.split('‚Ä¢', 1))
            else:
                published_time = pub_info.strip()

            pub_date = dateparser.parse(published_time)
            if pub_date is None or pub_date < cutoff_time:
                continue

            unique_key = title + pub_date.strftime('%Y-%m-%d')
            if unique_key in existing_titles:
                continue

            news_data.append({
                'company': ticker,
                'title': title,
                'published_date': pub_date.strftime('%Y-%m-%d')
            })

            existing_titles.add(unique_key)

        except Exception as e:
            print(f"‚ùå Error parsing article for {ticker}: {e}")
            continue

driver.quit()

if news_data:
    new_df = pd.DataFrame(news_data)
    new_df.to_csv(output_path, mode='a', header=not os.path.exists(output_path), index=False, encoding='utf-8-sig')
    print(f"\n‚úÖ ƒê√£ l∆∞u {len(new_df)} b√†i vi·∫øt v√†o '{output_path}'")
else:
    print("\n‚ö†Ô∏è Kh√¥ng c√≥ tin t·ª©c m·ªõi ƒë·ªÉ l∆∞u.")
